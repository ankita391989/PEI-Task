#1. Create Raw tables for each source dataset

#Including sanitization of the column names

import pandas as pd
import json
from datetime import datetime
import pytest

# Load Orders JSON file
with open('/Volumes/workspace/default/temp/Orders.json', 'r') as f:
    orders_data = json.load(f)
orders_df = pd.DataFrame(orders_data)

# Load Products CSV
products_df = pd.read_csv('/Volumes/workspace/default/temp/Products.csv')

# Load Customer Excel file  
customers_df = pd.read_excel('/Volumes/workspace/default/temp/Customer.xlsx')

# To apply stricter conventions (lowercase, replace spaces/hyphens with underscores, remove non-alphanumeric except underscore)

def sanitize_column(col):
    import re
    col = col.strip().lower()
    col = re.sub(r'[\s\-]+', '_', col)           # Replace spaces/hyphens with underscore
    col = re.sub(r'[^a-z0-9_]', '', col)         # Remove non-alphanumeric except underscore
    return col

orders_df.columns = [sanitize_column(c) for c in orders_df.columns]
products_df.columns = [sanitize_column(c) for c in products_df.columns]
customers_df.columns = [sanitize_column(c) for c in customers_df.columns]

# Ensure all phone numbers are strings in customers_df
if 'phone' in customers_df.columns:
    customers_df['phone'] = customers_df['phone'].astype(str)

# Convert to Spark DataFrames
spark_orders_df = spark.createDataFrame(orders_df)
spark_products_df = spark.createDataFrame(products_df)
spark_customers_df = spark.createDataFrame(customers_df)

# Overwrite tables with new schema
spark_orders_df.write.mode("overwrite").option("overwriteSchema", "true").saveAsTable("orders")
spark_products_df.write.mode("overwrite").option("overwriteSchema", "true").saveAsTable("products")
spark_customers_df.write.mode("overwrite").option("overwriteSchema", "true").saveAsTable("customers")
