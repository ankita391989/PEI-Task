#3c. Create an enriched table which has orders Information_Products Category

# Group the spark_orders_df DataFrame by 'product_id' and calculate metrics for each product

# Ensure spark_products_df is a Spark DataFrame
if 'spark_products_df' not in locals() or not hasattr(spark_products_df, 'join'):
    spark_products_df = spark.table("products")

    spark_orders_df = spark_orders_df.withColumn(
    'order_date', to_date('order_date', 'd/M/yyyy')
)
product_metrics = spark_orders_df.groupby('product_id').agg(
    # Count distinct 'order_id' to calculate the total number of orders for each product
    F.countDistinct('order_id').alias('total_orders'),
    
    # Sum the 'price' column to calculate the total sales revenue for each product
    F.sum('price').alias('total_sales'),
    
    # Sum the 'profit' column to calculate the total profit generated by each product
    F.sum('profit').alias('total_profit'),
    
    # Sum the 'quantity' column to calculate the total quantity sold for each product
    F.sum('quantity').alias('total_quantity_sold'),
    
    # Count distinct 'customer_id' to calculate the number of unique customers who purchased each product
    F.countDistinct('customer_id').alias('unique_customers')
)

# Round the 'total_sales' column to 2 decimal places for better readability and precision
product_metrics = product_metrics.withColumn('total_sales', F.round('total_sales', 2)) \
                                .withColumn('total_profit', F.round('total_profit', 2))

# Perform a left join between spark_products_df and product_metrics on the 'product_id' column
# Join with product details, Left join 
enriched_products = spark_products_df.join(product_metrics,
                                    on='product_id',
                                    how='left')

display(enriched_products)

# Display the enriched_products DataFrame, which now contains product details along with aggregated metrics
display(enriched_products)